# Spark 개요
## Spark이 개선한 단점들
1. HDFS의 파일시스템 기반 연산 처리 -> Spark의 메모리 기반 처리 (성능 up)
2. 자바 기반, 한정적인 맵리듀스 패턴, 한정적 SQL -> 자연스러운 데이터 처리 함수
3. 직접 순차적으로 실행해야 하는 맵리듀스 잡 -> 최적의 처리 흐름을 작업 실행 전에 찾음

## 데이터 모델
1. RDD
    * 다수의 서버에 걸쳐 분산 방식으로 저장된 데이터 요소들의 집합
    * 추상적인 데이터 모델이자, 동시에 프로그래밍 API
    * 병렬 처리 가능
        - `파티션`: 하나의 RDD에 속한 요소를 나눌 수 있는 단위. 이 단위로 나눠서 병렬 처리. 
        - `셔플링`: 어떤 파티션의 데이터가 작업 중 네트워크를 타고 다른 서버의 파티션으로 이동 (성능에 영향 미침 -> 파티션 개수 지정 옵션 있음)
    * 장애 발생시 스스로 복구
        - 일종의 클래스: 단순히 값으로 표현되는 데이터 + `데이터를 다루는 방법`
        - 파티션 처리에 장애 -> 결과 유실 -> RDD 생성 과정을 기록(`리니지`)해 둔 걸 보고 복구 (문제 생긴 부분 재수행)
            + 복구의 기본 원칙: 한번 생성된 RDD는 변경되지 않는다 (즉, RDD는 읽기 전용, 불변)
            + 연산: 기존 RDD -> 연산 -> 기존 RDD, 연산이 적용된 새로운 RDD
            + 복구는 `스파크 애플리케이션이 정상 동작하는 상황`인 경우에 한함. 애플리케이션/Driver 문제거나 앱-서버 통신 장애의 경우 RDD 복구 대상이 아님.
    * RDD 만들기
        1. 메모리에 있는 기존에 생성된 데이터 이용 ex. List, Set
        2. 로컬/하둡 파일시스템에서 데이터 읽어 생성
        3. RDD로부터 다른 RDD 생성
    * RDD가 제공하는 연산
        1. `Transformation` (RDD에 변형을 가해 `새로운 RDD` 생성하는 연산)
              + ex. [1,2,3] -(T: +1)-> [1,2,3], [2,3,4] 
        2. `Action` (어떤 동작을 실행해 `RDD가 아닌` 결과를 얻는 연산)
              + ex. [2,3,4] -(A: 갯수?)-> 3
        + cf. Rich API: 요소의 타입에 따라 사용 가능한 메서드가 다름.
2. Dataset
    * RDD의 확장
    * 코드 작성 언어의 데이터 타입 사용 가능하나, 그것과 스파크 데이터 타입 매핑하는 인코더 필요
3. DataFrame
    * RDD의 확장, 내부 처리 방법이 다름
    * RDD가 데이터 처리 함수를 직접 전달한다면, 데이터프레임은 내장함수와 표현식 등 간접 처리
        + 내부 함수, 사전 정의 표현식 -> 논리적 작업 트리 변환 -> 전반적인 최적화 -> 수행!
        + 훨씬 광범위하고 효율적인 최적화 ex. 바이트코드 생성하여 CPU 부하 최소화, 최적화 클래스 사용 등
        + 언어에 구애 받지 않음 (코드로 작성된 것이 실제 실행에 영향 미치지 않음)
    * 스파크에서 정의한 Row라는 타입의 객체로만 구성된 데이터셋의 특별한 형태 (`DataSet[Row]` by Scala type alias)

## DAG
- 방향이 있는 선, 노드로 구성되고, 어느 노드에서 시작해도 다시 출발 노드로 돌아오지 않는 그래프
- 복잡한 작업 흐름을 표현하기 위해 사용
- 예: Oozie (워크플로우 시스템, 스케줄링, 라이브러리 조합해서 사용 가능, XML)
- Spark의 DAG
    * by DAG 스케줄러
    * Spark는 전체 작업을 stage 단위로 나누고, stage를 task로 나눔
    * 과정
        1. Driver 프로그램이 SparkContext로 RDD의 연산 정보를 DAG 스케줄러에 전달
        2. DAG 스케줄러가 실행 계획(지역성 up)을 만들어서 클러스터 매니저에 전달
    * SparkContext, SparkSession
        - Spark 애플리케이션 - Spark 클러스터 간 연동 담당
            + 2.0 이전: SparkContext(백엔드), SQLContext(메타 정보)
            + 이후: SparkSession (SparkContext도 세션의 속성 중 하나로 정의, 호환을 위한 API 위임)
        - 애플리케이션이 동작하기 위한 서버 역할
            + 클러스터 구성 서버 간 데이터 통신을 위한 백엔드
            + 개별 작업 수행에 필요한 메타 정보 저장 및 관리
    * 좁은 의존성, 넓은 의존성
        - 좁은: 부모 RDD 파티션 -> 하나의 자식 RDD 파티션 (부모자식간 파티션 구성 같음)
        - 넓은: 부모 RDD 파티션 -> 다수의 자식 RDD 파티션 (셔플링 ㅇ, 튜닝 고려)

## Lazy Evaluation
- Transformation은 그 RDD를 사용하는 Action 호출 전까지 실제로 Transformation을 수행하지 않음
- 장점: 지역성 최적화 -> 불필요한 네트워크 통신 줄임
- 단점: Action이 두 번 호출되면 Transformation도 두 번 호출됨. 적절하게 캐싱하는 것이 필요.

## 람다 아키텍처
- [구조도](http://lambda-architecture.net/)
- 데이터 처리 시스템 = 일괄 처리 영역 (일괄 처리 계층) + 실시간 처리 영역 (속도 계층)
    * Spark-> 일괄 처리(spark), 속도(spark-streaming)
- 새로운 데이터는 두 영역 모두에 전달, 일괄 처리 작업으로 데이터 처리하되 배치 처리되지 않은 부분은 속도 계층이 보완, 결과를 조합해 사용자에게 전달
- 포인트: 적절한 조합 방법, 장애 복구 상황 대처

## Spark Cluster
- 스파크는 클러스터(여러 서버가 한 대의 서버처럼 동작하는 것) 환경에서 동작
- 대량 데이터를 여러 서버에 나누어 병렬 처리
- 고려할 것들: 네트워크, 장애, 스케줄링 등

## HDFS와의 관계
- 스파크는 하둡의 파일 입출력 API에 의존성을 가짐
- 하둡이 지원하는 입출력 포맷 + 자체적 데이터 타입 지원
- 하둡은 설정된 분할 정책에 따라 데이터를 블록 단위로 분할함. 기본적으로 1 HDFS 블록당 1 스파크 파티션으로 구성되나, 조정 가능.

## 기타
- 스파크 Job을 실행하면 서버마다 executor라는 프로세스가 생성되어 할당된 파티션 처리
- Driver
    * 메인 함수를 실행해서 RDD 생성 및 각종 연산 호출하는 프로그램
    * 정확히는 SparkContext를 생성하고 그 인스턴스를 포함하는 프로그램
    * 자신을 실행한 서버(보통 클러스터 안에 없는 별도의 작업 서버를 사용함)에서 클러스터의 워커 노드에게 작업 지시 & 결과 취합