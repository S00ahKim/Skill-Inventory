# Apache Kafka

## 요약
1. 분산 이벤트 스트리밍 플랫폼
2. 컨셉
   1. 데이터 전송에 있어 source app - target app간 커플링을 약하게 함
   2. 소스 앱은 어떤 데이터든 카프카에 넣을 수 있음
   3. 데이터를 담는 일종의 queue인 `토픽`, 토픽에 데이터를 넣는 `프로듀서`, 데이터를 가져가는 `컨슈머`
   4. 구성 요소가 라이브러리로 되어 있어 애플리케이션 구현에 용이
3. 장점
   1. 고가용성
       * 무손실 복구
   2. 성능 (높은 처리량)
       * OS 페이지 캐시에 의존
       * 묶어서 보내기 가능 (프로듀서, 컨슈머 모두)
   3. 낮은 지연
4. 단순성
    * 타 메시징 시스템 대비 단순한 브로커
    * 개발 배경: 데이터 전송이 많아질수록 갯수가 늘어나면서 복잡해지고, 전송 라인이 많아지고, 배포와 장애 대응이 어려워지고, 포맷이 많아져서 유지보수가 어려워졌기 때문에 이 문제를 해결하기 위해 링크드인 내부적으로 개발함.
    * 시스템의 수평적 확장이 쉬움


## 구성요소
### 1. 토픽 
1. 역할: 데이터를 넣는 큐
    * 토픽의 이름은 토픽의 쓰임새에 맞게 짓기
2. 특징
    * 토픽 하나는 여러 개의 파티션으로 구성됨
        + 저장될 파티션은 key로 정해짐
        + 기본 파티셔너 기준: 키가 없으면 라운드 로빈, 있으면 해시값 사용
        + 파티션을 늘릴 순 있지만 줄일 순 없기 때문에 주의 필요
        + 늘리면 컨슈머 늘려서 처리 분산 가능
    * 후입선출
    * 컨슈머가 데이터를 가져가도 삭제되는 것은 아님
        + 새 컨슈머가 붙을 경우 다시 0번부터 가져가게 할 수 있음 if 컨슈머 그룹 다름 && `auto.offset.rest=earliest`
        + 한 번 보내서 하둡에 백업하고 엘라스틱서치로 시각화하게 할 수 있는 것
    * 레코드 저장 최대시간(`log.retention.ms`)과 크기(`log.retention.byte`) 지정 가능

### 2. 프로듀서
1. 역할: 데이터를 카프카 토픽에 생산 (카프카 클러스터에 메시지 보냄)
    * 대량데이터를 대량, 실시간으로 적재할 때
    * 특정 토픽으로 데이터를 생성(or `publish` or `send`) & 처리 실패 건에 대해 재시도
2. 특징
    * gradle/maven에 라이브러리를 추가해서 사용 가능
        + 브로커 버전, 클라이언트 버전의 하위 호환성이 완벽하지 않음
        + [참고: 아파치 카프카 버젼별 하위호환](https://blog.voidmainvoid.net/193)
    * 자바 프로퍼티 객체로 설정 정의
    * 인스턴스를 만들 때 브로커는 2개 이상 권장
    * ProducerRecord 인스턴스로 어느 토픽에 넣을지send 설정 가능 (key는 옵션)
    * key의 갯수와 토픽의 갯수가 같으면 1:1 대응이 되는데 거기에서 하나 더 늘리면 대응이 깨짐. 설계 단계에서 잘 고려하고 추가 지양.

### 3. 컨슈머
1. 역할: 메시지(토픽 데이터)를 카프카에서 읽어오고 필요한 처리를 함
    1. 토픽 내부의 파티션으로부터 데이터 폴링(polling)
        * 폴링? 데이터를 가져오는 것
        * 데이터를 가져와서 특정 DB나 다른 파이프라인에 전달함
    2. 파티션 오프셋 위치 기록(commit)
        * 오프셋(offset)? 파티션에 있는 데이터 번호. 
            - 들어갈 때 지정
            - 파티션/토픽별로 다르게 지정
            - 컨슈머가 데이터를 어느 지점까지 읽었나 확인하는 용도(오프셋 정보가 `__consumer_offset`에 저장) -> 문제가 생겨도 복구 가능
    3. 컨슈머가 여러개일 때, 컨슈머 그룹을 통해 병렬 처리
2. 특징
    * 프로듀서와 마찬가지로 gradle/maven에 라이브러리를 추가해서 사용 가능
    * KafkaConsumer 인스턴스
        + `subscribe` 메서드로 어느 토픽에서 데이터를 가져올지 선언 (브로커는 config로 설정)
        + `assign` 메서드로 특정 토픽의 일부 파티션의 데이터를 가져올지 선언 (key가 있다면 여기서 순서 보장 가능)
        + `poll` 메서드로 데이터를 가져옴 (폴링 루프 = poll 메서드가 포함된 무한 루프) 
            - 인자로 데이터를 기다릴 시간ms을 설정 가능
            - 리턴값은 ConsumerRecord 타입. 이게 가장 작은 단위. 실제 데이터는 해당 타입의 value().
    * 타 메시징 플랫폼과 달리, 컨슈머가 데이터를 가져가도 데이터가 사라지지 않음 -> 데이터 파이프라인 운용의 핵심

### 4. 카프카 클러스터
1. 역할: 메시지를 저장하는 저장소
2. 특징
    * 여러 브로커로 구성
    * 브로커? 카프카가 설치된 각각의 서버 단위. 
        + 최소 2개, 일반적으로 3개의 브로커 권장
        + 메시지를 나눠 저장, 이중화 처리, 장애 대응 등

### 5. 주키퍼
1. 역할: 카프카 클러스터 관리
    * 주키퍼 클러스터 = 앙상블
    * 카프카 클러스터 관련 정보 기록 및 관리
2. 특징

## 고가용성
1. Replication
    * 장애가 생길 때 가용성을 보장해주는 카프카 아키텍처의 핵심
    * 브로커 갯수에 따라 레플리카 갯수 제한 (브로커 총 갯수보다 레플리카 갯수가 많을 수 없음)
    * 브로커에 문제가 생길 때 레플리카로만 복구 가능
2. ISR (In Sync Replica)
    * ISR = leader + follower
    * 원본 파티션 = leader partition, 나머지 = follower partition
    * 리더로만 메시지를 처리하며, 팔로워는 리더 복제만 함. 리더가 장애날 경우 팔로워가 리더가 됨.
3. 주의
    * 레플리케이션을 `1로 설정` = 파티션 1개, `2로 설정` = 원본 1 복제 1 (총 2) 의 식으로 생성
    * 프로듀서에서 ack 옵션을 `0으로 설정` = 리더 적재, 결과 모름, `1으로 설정` = 리더 적재, 결과 받음, `all로 설정` = 리더 적재, 복제 결과 받음 (속도는 느림)
    * 레플리카 양이 많아지면 브로커 리소스 사용량도 늘어나니까 데이터량, 저장 시간을 고려하여 갯수 정하자. `추천: 3개 이상 브로커 = 3개 레플리카`


### References
- [아파치 카프카 (데브원영)](https://www.youtube.com/channel/UCPdTFQUHzAzFobngtw1sFKg)
- [kafka 조금 아는 척하기 (최범균)](https://www.youtube.com/watch?v=0Ssx7jJJADI&ab_channel=%EC%B5%9C%EB%B2%94%EA%B7%A0)