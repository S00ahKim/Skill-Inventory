# Kafka Broker
> 프로듀서와 컨슈머, 두 클라이언트 사이에서 데이터 저장과 관리를 담당하는 서버


## 개요
- 역할: 프로듀서로부터 데이터 쓰기 요청이 오면 파일 시스템에 토픽 단위로 데이터를 분류해서 저장
- 저장 과정: 토픽 단위로 분리 -> 여러 개의 파티션으로 분리 -> 클러스터에 분산되어 저장
- 특징
    * 어떤 컨슈머가 데이터를 사용할지는 저장하지 않음
    * 서버의 대수와는 무관하게 무조건 클러스터를 구성하게 되어 있음. 1 서버에 1 카프카 브로커 프로세스.
    * 고가용성: replication (by 주키퍼 서버) 


## 데이터 복제와 싱크
- replication -> fault tolerant system
- 복제는 파티션 단위
    * 토픽 생성시, 파티션 복제 개수replication factor 함께 설정 (토픽마다 다를 수 있음)
    * 최소값 1 (=복제하지 않음), 최대값 브로커 개수
- 복제된 파티션 -> 리더 & 팔로워
    * 리더: 프로듀서/컨슈머와 직접 통신하는 파티션
    * 팔로워: 나머지 복제 데이터를 가지는 파티션. 리더의 오프셋 확인 -> 자신의 것과 차이가 있으면 가져옴 (=복제)
- 리더가 있는 브로커에 문제가 생길 경우, 팔로워 중 하나가 리더가 됨


## 컨트롤러
- 브로커 중 하나가 컨트롤러 역할을 함
- 역할: 다른 브로커 상태 체크, 브로커가 클러스터에서 빠지면 리더를 재분배
- 컨트롤러가 있는 브로커에 문제가 생길 경우, 다른 브로커 중 하나가 컨트롤러가 됨


## 코디네이터
- 브로커 중 하나가 코디네이터 역할을 함
- 역할: 컨슈머 그룹 상태 체크, 파티션을 컨슈머와 매칭되도록 분배, 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 컨슈머에 할당(=리밸런스)


## 데이터 삭제
- 브로커만 데이터 삭제 가능: 컨슈머가 데이터를 가져가도 토픽의 데이터는 삭제되지 않고, 컨슈머/프로듀서가 삭제를 요청할 수 없음
- 데이터 삭제는 파일 단위(log segment)
    * 세그먼트에는 다수의 데이터가 들어 있어서 특정 데이터만 골라서 삭제할 수 없음
    * 데이터가 쌓이는 동안 파일 시스템으로 열려 있음
    * `log.segment.bytes` 또는 `log.segment.ms`의 값에 따라 닫힘. 기본값은 1GB.
    * 설정값이 너무 작으면 데이터 저장 중 세그먼트 파일을 자주 여닫게 되어 부하 발생 가능
    * 닫힌 세그먼트 파일은 `log.retention.bytes` 또는 `log.retention.ms`의 값에 따라 삭제됨
    * 삭제를 위해 체크하는 시간 간격은 `log.retention.check.interval.ms`에 따름
- 삭제하지 않고 메시지 키 기준으로 오래된 데이터를 압축할 수 있음


## 컨슈머 오프셋 저장
- 컨슈머 그룹은 토픽이 특정 파티션에서 데이터를 어디까지 가져갔나를 확인하기 위해 오프셋을 커밋함
- 커밋한 오프셋은 __consumer_offsets 토픽에 저장됨


## References
- 아파치 카프카 애플리케이션 프로그래밍 (최원영)
- 스파크2 프로그래밍 (백성민)