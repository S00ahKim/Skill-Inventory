# Trino
> 하나 혹은 그 이상의 서로 다른 데이터 소스로 분산된 거대한 데이터셋에 대한 쿼리를 수행하기 위해 디자인된 분산 SQL 쿼리 엔진


## 트리노란?
- 대규모 데이터에 대한 분산 쿼리를 효율적으로 하기 위함
- DW와 OLAP을 위해 디자인됨 (분석, aggregation, 리포트 등)
- 하둡과 함께 쓰일 수 있으나, 그에 국한되지 않음


## Concepts
> stages가 어떻게 task에 매핑되는지, task는 어떻게 데이터를 처리하는 driver 셋을 보유하는지
- 서버 타입
    * 각 서버는 REST API로 다른 서버와 통신
    * coordinators
        + `brain`. 클라이언트가 실행을 위한 statement를 제출하는 노드.
        + 모든 트리노에는 코디네이터와 워커가 하나 이상 있어야 함. 개발/테스트 용도로만 한 노드에 두 역할 부여 가능.
        + 역할
            1. 구문 분석 (parsing statement)
            2. 쿼리 계획 (planning queries) - 쿼리 실행 조정. 실행 단계를 포함한 논리 모델 생성 -> 워커에서 실행할 작업으로 변환
            3. 트리노 워커 노드 매니징 (워커 활동 추적)
    * workers
        + 작업 실행, 데이터 처리 담당
        + 커넥터에서 데이터를 가져오고, 중간 데이터를 서로 교환함
        + 코디네이터는 워커에서 처리 결과를 가져와 클라이언트에 반환함 (워커는 작업 시작시 코디네이터에게 알림)
- 데이터 소스
    * connector
        + 일종의 데이터베이스용 드라이버
        + 트리노를 하이브나 여타 RDB와 같은 데이터 소스와 상호작용할 수 있도록 함
        + 모든 카탈로그는 특정 커넥터와 연결됨 (같은 커넥터를 공유 가능)
        + ex. JMX용 커넥터, 내장 시스템 테이블에 대한 액세스를 제공하는 시스템 커넥터, Hive 커넥터, TPC-H 벤치 마크 데이터를 제공하도록 설계된 TPCH 커넥터 등
    * catalog
        + 커넥터로 데이터 소스를 참조함
        + 스키마를 가짐. 카탈로그와 스키마는 쿼리할 수 있는 테이블 셋을 함께 정의함.
        + SQL을 실행 -> 하나 이상의 카탈로그에 대해 실행
        + `hive.test_data.test`으로 선언된 테이블은 hive 카탈로그의 test_data 스키마의 test 테이블을 말함
        + 트리노 conf 디렉토리 하에 프로퍼티 파일로 정의됨
    * schema
        + 테이블을 구성하는 방법
        + RDB에 액세스할 때, RDB에서 사용하는 스키마와 같은 개념으로 변환됨
        + 다른 DB에 액세스할 땐 해당 데이터 원본에 적합한 방식으로 스키마를 구성
    * table 
        + 일반적인 RDB와 동일함 (타입이 있는 열column들로 조직된 순서가 없는 행row의 집합)
        + 소스 데이터 -> 테이블로의 매핑은 커넥터가 정의함
- 쿼리 실행 모델
    * 트리노는 SQL statement를 실행하고, 이를 코디네이터와 분산 클러스터에서 실행되는 쿼리로 변환함
    * Statement
        + ANSI 호환 (특정 벤더에 종속적이지 않은 표준 SQL)
        + statement와 query를 구분하는 이유?
            - statement는 단순한 텍스트적 표현. 트리노에 전달되는 SQL 텍스트.
            - query는 statement가 실행하고 나서 트리노가 워커들에 분산할 쿼리 플랜과 함께 만드는 것
    * Query
        + 스테이트먼트 --(트리노 파싱)--> 스테이트먼트를 쿼리로 변환 & 분산 쿼리 플랜 생성
        + 쿼리 플랜? 트리노 워커에 실행되는 상호 연결된 stages로 실현됨
        + 쿼리의 응답? 결과 집합을 생성하는 데 관련된 모든 컴포넌트의 스냅샷
        + 쿼리는 스테이트먼트 실행을 위한 configuration과 인스턴스화된 components를 참조함.
          쿼리는 결과를 실행하기 위해 함께 작동하는 stage들, task들, split들, connector들, 기타 컴포넌트들, 데이터 소스들이 포함됨
    * Stage
        + 쿼리 실행은 스테이지들의 계층으로 쪼개짐
        + 스테이지는 코디네이터가 분산 쿼리 계획을 모델링하는 데 사용
        + 스테이지 자체를 트리노 워커에서 실행하는 것이 아님
        + hierarchy of stages
            - 트리 구조
            - 모든 쿼리에는 다른 stage의 출력을 집계하는 루트 stage가 있음 
        + ex. Trino가 Hive에 저장된 10억 개의 행에서 데이터를 집계해야하는 경우, 분산 쿼리 계획의 다른 섹션을 구현하도록 설계된 다른 여러 스테이지의 출력을 집계하는 루트 스테이지를 생성하여 수행
    * Task
        + 스테이지의 실행: 트리노 워커 네트워크를 통해 분산된 일련의 태스크들로 구현되어 이루어짐
        + 태스크는 인풋, 아웃풋을 가짐
        + 태스크들로 스테이지를 병렬 처리할 수 있듯이, 드라이버들로 태스크를 병렬 처리할 수 있음
        + 분산 쿼리 플랜 --> 스테이지들로 분해 --> 태스크들로 변환 --> 스플릿을 처리
    * Split
        + 태스크는 보다 큰 데이터 셋의 섹션인 스플릿에 대해 실행됨
        + 분산 쿼리 플랜 중...
            - 가장 낮은 수준에 있는 스테이지: 커넥터에서 스플릿을 통해 데이터를 검색
            - 더 높은 수준의 중간 스테이지: 다른 스테이지에서 데이터를 검색
        + 트리노가 쿼리를 스케줄링할 때, 코디네이터는 커넥터에 테이블에 사용 가능한 모든 스플릿 리스트를 질의함
        + 코디네이터는 어떤 컴퓨터가 어떤 태스크를 실행하고, 어떤 스플릿이 어떤 태스크에 의해 처리되는지 추적함
    * Driver
        + 태스크는 하나 이상의 병렬 드라이버를 포함함
        + 데이터에 따라 작동
        + `일련의 오퍼레이터 인스턴스`거나, `메모리의 물리적 오퍼레이터 집합`으로 여길 수 있음
        + 트리노 아키텍처상 가장 낮은 수준의 병렬 처리
        + 하나의 입력, 하나의 출력
        + 역할: 오퍼레이터 결합하여 아웃풋 생산, 태스크에 의해 집계, 다른 스테이지의 다른 태스크로 전달
    * Operator
        + 오퍼레이터는 데이터를 소비(consume), 변환(transform) 및 생성(produce)함
        + ex. table scan: 커넥터에서 데이터를 가져옴 -> 다른 오퍼레이터가 사용할 수 있는 데이터 생성
        + ex. filter 오퍼레이터: 데이터 소비, 인풋 데이터에 predicate을 적용하여 서브셋 생성
    * Exchange
        + 쿼리의 여러 단계를 위해 트리노 노드 간에 데이터를 교환(exchange)
        + 작업은 출력 버퍼로 데이터를 생성하고 교환 클라이언트를 사용하여 다른 작업의 데이터를 소비


## Reference
- [Trino Docs](https://trino.io/docs/current/overview.html)
- [Presto, Trino 개념 및 사용법 정리](https://jsonobject.tistory.com/564)